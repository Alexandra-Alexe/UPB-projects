## STATISTICI SPORTIVE - TEMA 1 - ASC 

Prin această tema am implementat un server în python care gestionează o serie de requesturi bazate pe un set de date în format csv. Serverul oferă statistici pe baza fișierului csv. Ideea de rezolvarea a temei a fost de a ma folosi de un numar mare de threaduri pentru rezolvarea eficientă a cererilor. Fiecarui request i se atribuie un job_id, care este retinut alaturi de date si de un identificator, într-un tuplu ce va fi util în funcția de run a threadurilor, acolo unde se va calcula rezulatul și sa va scrie într-un fișier specific. Consider ca tema a fost utilă deoarece am aprofundat utilizarea eficientă a elementelor de sincronizare. Consider că e implementarea mea este una concisă și corectă. Trebuie să menționez faptul că am realizat implementarea fișierelor de logging, dar nu am facut unittesting.


    Implementarea din fișierul data_ingestor.py se ocupă de prelucrarea datelor din fișierul csv și 
returnarea unui dicționar ce conține doar datele necesare. În metoda __init__ se folosește calea primită ca parametru pentru a se citi din fișier prin metoda load_csv_file. Ulterior se extrage prima linie ca și cap de tabel, cu ajutorul căreia se indentifică indecșii coloanelor necesare în prelucrare. Apoi se iterează prin restul fișierului, se rețin valorile coloanelor importante și se adugă în dicționar fie ca intrare nouă, fie se adugă alături de alte intrări ale aceleiași întrebări. Ca 2 liste ale clasei, sunt reținute înttrebările posibile.

    În fișierul routes.py se găsesc funcțiile care indică existentă unui 
request de un anumit tip. States_mean este un request de tip post, care primește întrebarea sa prin variabila data. Funcția incrementează un contor pentru a îi asocia requestului un job id. Se creează un tuplu format din datele primite, id-ul jobului și tipul de request. Acest tuplu se adugă în coada asociată serverului. Tot aici, se salvează în cadrul unui dicționar pairs, ascocierea dintre id si statusul prelucrării care este setat deja la running. Se returnează în format json un șir ce conține id-ul jobului. În cazul în care request-ul primit nu este de tip POST, se returnează un mesaj de eroare.
Restul requesturilor de tip post sunt implementate în mod asemănător requestului states_mean, existând diferența tipului. Așadar în funcție de tipul de request, prelucrarea datelor sa va face diferit mai departe. Graceful_shutdown este un request de tip get prin care se verifică dacă toate prelucrările au fost îndeplinite, caz în care se dă join firelor de execuție și se seteaza cu true flag-ul pentru încheiere. Num_jobs este un request de tip get prin care se returnează numărul de joburi nefinalizate, după ce se verifică faptul că nu a fost activat flag-ul de închidere. Jobs este un request de tip get prin care se transmit perechile de job id-uri si statusul fiecăruia. Acest lucru se face în mod direct prin dicționarul pairs. Get_results este un request care întorce fie eroare, fie statusul de running, fie rezultatul prelucrării în cazul în care este disponibil. Acestă implementare se face în primul rând prin verificarea statusului și ulterior prin verificarea existenței fisierului results din care să se poată citi. Dacă statusul nu este "done", atunci se va verifica și se va întoarce "running", iar dacă există probleme în aceesarea rezultatului prelucrării, se transmit erori. Altfel, sunt citite datele și sunt returnate cu statusul "done".

 - Clasa ThreadPool: 
    În constructorul clasei, sunt inițializate variabilele necesare,
apelându-se metoda _get_thread_count() prin care se obține numărul de threaduri suportate de sistem. Tot aici, este creat directorul results, în care se vor afla fișierele cu rezultate. Ulterior, se crează threadurile prin apelul constructorului din clasa TaskRunner și apoi fiecare este adăugat în pool și este pornit.

 - Clasa TaskRunner: 
    În metoda __init__() sunt stabilite variabilele necesare, precum și 
calea spre directorul cu rezultate. Aici se crează un obiect de tip data ingestor care conține informațiile necesare prelucrarii, preluate din fișierul dat, nutrition_activity_obesity_usa_subset.csv.
     În metoda run se verifică valorea flag-ului de shutdown și dacă nu 
este cazul unui semnal de oprire și dacă coada cu joburi nu este vida, se extrage câte unul. Așasar fiecare thread, obține câte o sarcină, execută functia execute_task() folosind tipul de task si datele din tuplu, iar dacă rezultatul obținut un este null, creează fișierul corespunzător și scrie rezultatul. Apoi, de identifică job-ul respectiv în dicționarul pairs și i se modifică statusul în "done".
    În metoda execute_task() se verifică în primul rând tipul de sarcină.
În implementare sunt grupate tipurile de sarcini asemănatoare,de exemplu, pentru următoarele tipuri: best5, worst5, states_mean, global_mean și diff_from_mean , este necesar un dicționar cu mediile valorilor Data_Value în funcție se stat. Așadar, dupa extragerea întrebării, se iterează doar prin intrările ce conțin acea întrebare, din dicționarul data_ingestor. Ulterior se verifică perioada de timp a datelor și faptul că valoarea numerică pt Data_Value este nenula, caz în care în total_values se adună suma tuturor valorilor și în total_entries se contorizează numărul de valori adunate. Acestea 2 variabile sunt ulterior utilizate în calculul mediei globale. Tot aici, se verifică dacă statul unei intrări a mai fost introdus în dicționarul states_values, și se acționează în consecință pentru a ține evidenta sumei valorilor și a numărului valorilor pentru fiecare stat în parte. Ulterior se iterează prin dicționar pentru a calcula mediile valorilor pentru fiecare stat. Returnarea rezulatului depinde de tipul requestului, așasar dacă a fost un request de tip best5 iar întrebarea primită a fost din categoria "best is min" sau daca este vorba despre tipul worst5 și categoria "best is max", se va face de fapt aceeași prelucrare. Se va sorta dicționarul crescător și se vor returna primele 5 intrări. Pentru cazul invers (best5 & best is max) & (worst5 & best is min), se procedează invers, sortându-se dicționarul descresctor. Pentru tipul states_mean, se face sortare și se returnează întreg dicționarul. Pentrul tipul global_mean, se retunează rezultatul împărțirii sumei de valori la numărul de valori, iar pentru diff_from_mean se iterează prin dicționarul sortat crescător, și se calculează diferența valorilor față de media globală.
    În cazul tipului state_mean și state_diff_from_mean se procedează în
mod asemănător cu precizarea că se ține cont ca locatița unei intrări să corespundă cu statul primit în datele requestului. Concomitent se calculează și aici suma valorilor globală, fiind necesară ulterior. Deci pentru tipul state_mean rezulatul va fi împărțirii sumei calculate la numărul de valori, iar pentru state_diff_from_mean, se finalizează calculul mediei gloable și se returnează diferența față de media pentru acel stat.
    În cazul tipului mean_by_category, se iterează prin intrările din data
ingestory ce corespund cu intrebarea data, se verifică existența datelor pe coloanele necesare, se realizează o cheie compusă din locație, categoria de stratificare și stratificarea, iar pentru fiecare tip de cheie, se rețin valorile în dicționarul mean_by_category. Ulterior se iterează prin el, se calculează mediile, și se formatează răspunsul astfel încat sa poată fi serializat ca json înainte de a fi returnat.
    Cazul state_mean_by_category funcționează în mod asemănător cu
mean_by_category, doar că locația nu va mai reprezenta un câmp al cheii din dicționarul rezultat, ci se va verifica ca locația intrărilor care se prelucrează, să corespundă cu statul impus.

    În fișierul logging.py am gestionat crearea fișierelor de log. Am stabilit
calea de stocare a fișierelor și am creat o funcție care să determine care este nume următorului fișier de log care trebuie creat, astfel încât să se respecte cerința. Am setat dimensiunea, nivelul de logging la INFO și am creat handler-ul respectând formatarea cu timestamp-ul în format gmtime. În implementare am adaugat instrucțiuni de scriere în fișierul webserver.log, la începutul și finalul funcțiilor, dar nu numai. De asemenea, unde a fost cazul unui acces concurent al threadurilor la variabile, am folosit lock-uri. 
